{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superb-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Requirement already satisfied: pyLDAvis in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (3.2.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (0.36.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (1.6.1)\n",
      "Requirement already satisfied: funcy in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (1.15)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (1.19.2)\n",
      "Requirement already satisfied: numexpr in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (1.2.2)\n",
      "Requirement already satisfied: future in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-herald",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "numeric-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-opinion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "three-pathology",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alive-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweet_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "southern-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jeremynewberger marklevinshow petehegseth we d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hawleymo simonschuster a lot of courts are goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frznsoonrmn missilmom wow  i wish this video w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wynk  will uniter president joe biden apologiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kittentalker usafreedom2020 stopthesteal godje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  jeremynewberger marklevinshow petehegseth we d...\n",
       "1  hawleymo simonschuster a lot of courts are goi...\n",
       "2  frznsoonrmn missilmom wow  i wish this video w...\n",
       "3  wynk  will uniter president joe biden apologiz...\n",
       "4  kittentalker usafreedom2020 stopthesteal godje..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "close-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "inner-literacy",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jeremynewberger marklevinshow petehegseth we d...\n",
       "1    hawleymo simonschuster a lot of courts are goi...\n",
       "2    frznsoonrmn missilmom wow  i wish this video w...\n",
       "3    wynk  will uniter president joe biden apologiz...\n",
       "4    kittentalker usafreedom2020 stopthesteal godje...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnSeriesObj = df_short['text']\n",
    "text = columnSeriesObj\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "criminal-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jeremynewberger marklevinshow petehegseth we do care where he goes who are you againstopthest'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-anaheim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sophisticated-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "danish-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'),\n",
    "                             return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "awful-ireland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "turned-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "manufactured-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f'Topic {topic_idx +1}',\n",
    "                     fontdict={'fontsize': 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        for i in 'top right left'.split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "outside-transsexual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-010a4e4d1203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m data, _ = df['text'](shuffle=True, random_state=1,\n\u001b[1;32m      4\u001b[0m                              \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'headers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'footers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quotes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                              return_X_y=True)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data, _ = df['text'](shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'),\n",
    "                             return_X_y=True)\n",
    "data_samples = data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "plot_top_words(nmf, tfidf_feature_names, n_top_words,\n",
    "               'Topics in NMF model (Frobenius norm)')\n",
    "\n",
    "# Fit the NMF model\n",
    "print('\\n' * 2, \"Fitting the NMF model (generalized Kullback-Leibler \"\n",
    "      \"divergence) with tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "plot_top_words(nmf, tfidf_feature_names, n_top_words,\n",
    "               'Topics in NMF model (generalized Kullback-Leibler divergence)')\n",
    "\n",
    "print('\\n' * 2, \"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "plot_top_words(lda, tf_feature_names, n_top_words, 'Topics in LDA model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-particle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-mixture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'images/LDAvis_20_eta01.html')\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
